"Particle.size",  "NM.Hazard","Administration.route",  "NM.Hazard",
"Study.type",  "NM.Hazard","Cytotoxicity",  "NM.Hazard",
"Neurological.effects",  "NM.Hazard", "Pulmonary.effects",  "NM.Hazard",
"Fibrosis",  "NM.Hazard", "RCNS.effects",   "NM.Hazard", "Genotoxicity",  "NM.Hazard",
"Inflammation", "Nanoparticle","Shape",
"Nanoparticle",  "Surface.reactivity", "Nanoparticle", "Neurological.effects",
"Nanoparticle", "Surface.coatings","Nanoparticle", "Surface.charge",
"Nanoparticle", "Administration.route", "Nanoparticle",  "Fibrosis",
"Shape","Genotoxicity","Surface.area", "Neurological.effects",
"Surface.coatings", "Surface.area",  "Surface.coatings",  "Particle.size",
"Surface.coatings", "Cytotoxicity", "Surface.coatings", "Pulmonary.effects",
"Surface.coatings", "Aggregation",   "Surface.coatings",  "Study.type",
"Pulmonary.effects", "Inflammation","Inflammation","RCNS.effects"),
ncol = 2, byrow = TRUE, dimnames = list(c(), c("from", "to")))
start <- 1
# Test cross-val accuracy of best model
for(i in 1: N_folds){
select <- start:(start+step-1)
if(i ==10){
select <- start:559
}
test <- data[select,]
#Extract observations
observed <- test$NM.Hazard
train <- data[-select,]
# fit the model
training.fit  <- bnlearn::bn.fit(ug, train, method="bayes") #method = "bayes"/"mle"
# Delete all observed nodes
for (k in 1:dim(test)[1]){
for (j in 11:18){
test[k,j] <- NA
}
}
N_test <- dim(test)[1]
pred <- rep(0, N_test)
# Convert all results to factors in order to calculate the confusion matrix
pred <- as.factor(pred)
observed <- as.factor(observed)
levels(pred) <- levels(observed)
for (j in 1:N_test){
# n : number of samples used to average
pred[j] <-  as.character(predict(training.fit, data=test[j,!is.na(test[j,])],
node= "NM.Hazard",prob = T, method = "bayes-lw", n=10000))
#method = "bayes-lw" / "parents"
}
mcc[[i]]  <- yardstick::mcc_vec(observed, pred)
conf[[i]]  <- tibble::tibble(truth = observed,
estimate = pred) %>%
conf_mat(truth, estimate)
acc[[i]]  <-  yardstick::accuracy_vec(observed, pred)#  # Update starting position of test
start <- start+step
}
jaqpotr
deploy.bn(trained.model = training.fit)
jaqpotr::deploy.bn(trained.model = training.fit)
devtools::install_github("euclia/jaqpotr")
object <- jsonlite::fromJSON("C:/Users/user/Desktop/Jaqpot/R/json/bnlearn.json")
dataset <- object$dataset
rawModel <- object$rawModel
additionalInfo <- object$additionalInfo
#################################
## Input retrieval from Jaqpot ##
#################################
# Get feature keys (a key number that points to the url)
feat.keys <-  dataset$features$key
# Get feature names (actual name)
feat.names <- dataset$features$name
# Create a dataframe that includes the feature key and the corresponding name
key.match <- data.frame(cbind(feat.keys, feat.names))
# Convert factor to string (feat.names is converted factor by data.frame())
key.match[] <- lapply(key.match, as.character)
# Initialize a dataframe with as many rows as the number of values per feature
rows_data <- length(dataset$dataEntry$values[,2])
df <- data.frame(matrix(0, ncol = 0, nrow = rows_data))
for(key in feat.keys){
# For each key (feature) get the vector of values (of length 'row_data')
feval <- dataset$dataEntry$values[key][,1]
# Name the column with the corresponding name that is connected with the key
df[key.match[key.match$feat.keys == key, 2]] <- feval
}
# Convert "NA" to NA
for (i in 1:dim(df)[1]){
for (j in 1:dim(df)[2]){
if(!is.na(df[i,j])){
if(df[i,j] == "NA"){
df[i,j] <- NA
}
}
}
}
# Extract the predicted value names
predicted.feats <- rep(0,  length(additionalInfo$predictedFeatures))
for (i in 1:length(predicted.feats)){
predicted.feats[i] <- additionalInfo$predictedFeatures[[i]]
}
###########################
## Model unserialization ##
###########################
mod <- unserialize(jsonlite::base64_dec(rawModel))
model <- mod$MODEL
method <- additionalInfo$fromUser$predict.args$method
n <- additionalInfo$fromUser$predict.args$n
# Convert categorical variables to factors
for (i in 1:dim(df)[2]){
varname <- names(df)[i]
if(varname !=  "query node"){
# Retrieve the levels from the model and convert to factor
df[,i] <- factor(df[,i], levels = attributes(model[[eval(expr(varname))]]$prob)$dimnames[[1]])
}
}
################
## Prediction ##
################
#Define a parameter to store thenumber of levels of each query nodes
level.count <- rep(NA,dim(df)[1] )
# Get output dimensions depending on the number of levels of each query node
for (instance in 1:dim(df)[1]){
pred.node <- as.character(df$`query node`[instance])
level.count[instance] <- length(levels(df[[eval(expr(pred.node))]]))
}
# Create a matrix to store the solution
prediction <- matrix(rep(NA,3*sum(level.count)), ncol = 3)
# Create a variable to store the last row filled in the prediction matrix
where <- 1
for (instance in 1:dim(df)[1]){
pred.node <- as.character(df$`query node`[instance])
#Provide only non NA values
newdata <-  df[instance,!is.na(df[instance,])]
# Remove the query node
newdata <-  newdata[ ,-which(names(newdata) == "query node")]
# Store in the first column the query node
prediction[where:(where+level.count[instance]-1),1] <- pred.node
# Make the prediction
result = attributes(predict(model, data = newdata, node= pred.node, prob = T, method = method, n = n))$prob[,1]
# Store in the seconde column the levels
prediction[where:(where+level.count[instance]-1),2] <- names(result)
# Store the probabilities returned by the model in the third column
prediction[where:(where+level.count[instance]-1),3] <- round(result,3)
#Update the row count
where <- where+level.count[instance]
}
colnames(prediction) <- c("query node", "prediction class", "probability")
##################################
## Name and return predictions  ##
##################################
for(i in 1:dim(prediction)[1]){
pred<- data.frame((t(prediction[i,])))
# Bring everything into a format that cooperates with Jaqpot
if(i==1){lh_preds<- list(jsonlite::unbox(pred))
}else{
lh_preds[[i]]<- jsonlite::unbox(pred)
}
}
datpred <-list(predictions=lh_preds)
object <- jsonlite::fromJSON("C:/Users/user/Desktop/Jaqpot/R/json/bnlearn.json")
dataset <- object$dataset
rawModel <- object$rawModel
additionalInfo <- object$additionalInfo
#################################
## Input retrieval from Jaqpot ##
#################################
# Get feature keys (a key number that points to the url)
feat.keys <-  dataset$features$key
# Get feature names (actual name)
feat.names <- dataset$features$name
# Create a dataframe that includes the feature key and the corresponding name
key.match <- data.frame(cbind(feat.keys, feat.names))
# Convert factor to string (feat.names is converted factor by data.frame())
key.match[] <- lapply(key.match, as.character)
# Initialize a dataframe with as many rows as the number of values per feature
rows_data <- length(dataset$dataEntry$values[,2])
df <- data.frame(matrix(0, ncol = 0, nrow = rows_data))
for(key in feat.keys){
# For each key (feature) get the vector of values (of length 'row_data')
feval <- dataset$dataEntry$values[key][,1]
# Name the column with the corresponding name that is connected with the key
df[key.match[key.match$feat.keys == key, 2]] <- feval
}
# Convert "NA" to NA
for (i in 1:dim(df)[1]){
for (j in 1:dim(df)[2]){
if(!is.na(df[i,j])){
if(df[i,j] == "NA"){
df[i,j] <- NA
}
}
}
}
# Extract the predicted value names
predicted.feats <- rep(0,  length(additionalInfo$predictedFeatures))
for (i in 1:length(predicted.feats)){
predicted.feats[i] <- additionalInfo$predictedFeatures[[i]]
}
###########################
## Model unserialization ##
###########################
mod <- unserialize(jsonlite::base64_dec(rawModel))
model <- mod$MODEL
method <- additionalInfo$fromUser$predict.args$method
n <- additionalInfo$fromUser$predict.args$n
# Convert categorical variables to factors
for (i in 1:dim(df)[2]){
varname <- names(df)[i]
if(varname !=  "query node"){
# Retrieve the levels from the model and convert to factor
df[,i] <- factor(df[,i], levels = attributes(model[[eval(expr(varname))]]$prob)$dimnames[[1]])
}
}
################
## Prediction ##
################
#Define a parameter to store thenumber of levels of each query nodes
level.count <- rep(NA,dim(df)[1] )
# Get output dimensions depending on the number of levels of each query node
for (instance in 1:dim(df)[1]){
pred.node <- as.character(df$`query node`[instance])
level.count[instance] <- length(levels(df[[eval(expr(pred.node))]]))
}
# Create a matrix to store the solution
prediction <- matrix(rep(NA,3*sum(level.count)), ncol = 3)
# Create a variable to store the last row filled in the prediction matrix
where <- 1
for (instance in 1:dim(df)[1]){
pred.node <- as.character(df$`query node`[instance])
#Provide only non NA values
newdata <-  df[instance,!is.na(df[instance,])]
# Remove the query node
newdata <-  newdata[ ,-which(names(newdata) == "query node")]
# Store in the first column the query node
prediction[where:(where+level.count[instance]-1),1] <- pred.node
# Make the prediction
result = attributes(predict(model, data = newdata, node= pred.node, prob = T, method = method, n = n))$prob[,1]
# Store in the seconde column the levels
prediction[where:(where+level.count[instance]-1),2] <- names(result)
# Store the probabilities returned by the model in the third column
prediction[where:(where+level.count[instance]-1),3] <- round(result,3)
#Update the row count
where <- where+level.count[instance]
}
colnames(prediction) <- c("query node", "prediction class", "probability")
##################################
## Name and return predictions  ##
##################################
for(i in 1:dim(prediction)[1]){
pred<- data.frame((t(prediction[i,])))
# Bring everything into a format that cooperates with Jaqpot
if(i==1){lh_preds<- list(jsonlite::unbox(pred))
}else{
lh_preds[[i]]<- jsonlite::unbox(pred)
}
}
datpred <-list(predictions=lh_preds)
length(levels(df[[eval(expr(pred.node))]]))
#################################
## Input retrieval from Jaqpot ##
#################################
# Get feature keys (a key number that points to the url)
feat.keys <-  dataset$features$key
# Get feature names (actual name)
feat.names <- dataset$features$name
# Create a dataframe that includes the feature key and the corresponding name
key.match <- data.frame(cbind(feat.keys, feat.names))
# Convert factor to string (feat.names is converted factor by data.frame())
key.match[] <- lapply(key.match, as.character)
# Initialize a dataframe with as many rows as the number of values per feature
rows_data <- length(dataset$dataEntry$values[,2])
df <- data.frame(matrix(0, ncol = 0, nrow = rows_data))
for(key in feat.keys){
# For each key (feature) get the vector of values (of length 'row_data')
feval <- dataset$dataEntry$values[key][,1]
# Name the column with the corresponding name that is connected with the key
df[key.match[key.match$feat.keys == key, 2]] <- feval
}
# Convert "NA" to NA
for (i in 1:dim(df)[1]){
for (j in 1:dim(df)[2]){
if(!is.na(df[i,j])){
if(df[i,j] == "NA"){
df[i,j] <- NA
}
}
}
}
# Extract the predicted value names
predicted.feats <- rep(0,  length(additionalInfo$predictedFeatures))
for (i in 1:length(predicted.feats)){
predicted.feats[i] <- additionalInfo$predictedFeatures[[i]]
}
###########################
## Model unserialization ##
###########################
mod <- unserialize(jsonlite::base64_dec(rawModel))
model <- mod$MODEL
method <- additionalInfo$fromUser$predict.args$method
n <- additionalInfo$fromUser$predict.args$n
# Convert categorical variables to factors
for (i in 1:dim(df)[2]){
varname <- names(df)[i]
if(varname !=  "query node"){
# Retrieve the levels from the model and convert to factor
df[,i] <- factor(df[,i], levels = attributes(model[[eval(substitute(varname))]]$prob)$dimnames[[1]])
}
}
################
## Prediction ##
################
#Define a parameter to store thenumber of levels of each query nodes
level.count <- rep(NA,dim(df)[1] )
# Get output dimensions depending on the number of levels of each query node
for (instance in 1:dim(df)[1]){
pred.node <- as.character(df$`query node`[instance])
level.count[instance] <- length(levels(df[[eval(substitute(pred.node))]]))
}
# Create a matrix to store the solution
prediction <- matrix(rep(NA,3*sum(level.count)), ncol = 3)
# Create a variable to store the last row filled in the prediction matrix
where <- 1
for (instance in 1:dim(df)[1]){
pred.node <- as.character(df$`query node`[instance])
#Provide only non NA values
newdata <-  df[instance,!is.na(df[instance,])]
# Remove the query node
newdata <-  newdata[ ,-which(names(newdata) == "query node")]
# Store in the first column the query node
prediction[where:(where+level.count[instance]-1),1] <- pred.node
# Make the prediction
result = attributes(predict(model, data = newdata, node= pred.node, prob = T, method = method, n = n))$prob[,1]
# Store in the seconde column the levels
prediction[where:(where+level.count[instance]-1),2] <- names(result)
# Store the probabilities returned by the model in the third column
prediction[where:(where+level.count[instance]-1),3] <- round(result,3)
#Update the row count
where <- where+level.count[instance]
}
colnames(prediction) <- c("query node", "prediction class", "probability")
##################################
## Name and return predictions  ##
##################################
for(i in 1:dim(prediction)[1]){
pred<- data.frame((t(prediction[i,])))
# Bring everything into a format that cooperates with Jaqpot
if(i==1){lh_preds<- list(jsonlite::unbox(pred))
}else{
lh_preds[[i]]<- jsonlite::unbox(pred)
}
}
datpred <-list(predictions=lh_preds)
datpred
df
prediction
length(levels(df[[eval(substitute(pred.node))]]))
attributes(model[[eval(substitute(varname))]]$prob)$dimnames[[1]]
df
#Define a parameter to store thenumber of levels of each query nodes
level.count <- rep(NA,dim(df)[1] )
# Get output dimensions depending on the number of levels of each query node
for (instance in 1:dim(df)[1]){
pred.node <- as.character(df$`query node`[instance])
level.count[instance] <- length(levels(df[[eval(substitute(pred.node))]]))
}
# Create a matrix to store the solution
prediction <- matrix(rep(NA,3*sum(level.count)), ncol = 3)
# Create a variable to store the last row filled in the prediction matrix
where <- 1
prediction
for (instance in 1:dim(df)[1]){
pred.node <- as.character(df$`query node`[instance])
#Provide only non NA values
newdata <-  df[instance,!is.na(df[instance,])]
# Remove the query node
newdata <-  newdata[ ,-which(names(newdata) == "query node")]
# Store in the first column the query node
prediction[where:(where+level.count[instance]-1),1] <- pred.node
# Make the prediction
result = attributes(predict(model, data = newdata, node= pred.node, prob = T, method = method, n = n))$prob[,1]
# Store in the seconde column the levels
prediction[where:(where+level.count[instance]-1),2] <- names(result)
# Store the probabilities returned by the model in the third column
prediction[where:(where+level.count[instance]-1),3] <- round(result,3)
#Update the row count
where <- where+level.count[instance]
}
library(bnlearn)
for (instance in 1:dim(df)[1]){
pred.node <- as.character(df$`query node`[instance])
#Provide only non NA values
newdata <-  df[instance,!is.na(df[instance,])]
# Remove the query node
newdata <-  newdata[ ,-which(names(newdata) == "query node")]
# Store in the first column the query node
prediction[where:(where+level.count[instance]-1),1] <- pred.node
# Make the prediction
result = attributes(predict(model, data = newdata, node= pred.node, prob = T, method = method, n = n))$prob[,1]
# Store in the seconde column the levels
prediction[where:(where+level.count[instance]-1),2] <- names(result)
# Store the probabilities returned by the model in the third column
prediction[where:(where+level.count[instance]-1),3] <- round(result,3)
#Update the row count
where <- where+level.count[instance]
}
colnames(prediction) <- c("query node", "prediction class", "probability")
##################################
## Name and return predictions  ##
##################################
for(i in 1:dim(prediction)[1]){
pred<- data.frame((t(prediction[i,])))
# Bring everything into a format that cooperates with Jaqpot
if(i==1){lh_preds<- list(jsonlite::unbox(pred))
}else{
lh_preds[[i]]<- jsonlite::unbox(pred)
}
}
datpred <-list(predictions=lh_preds)
datpred
prediction
datpred
getwd()
setwd("C:/Users/user/Documents/GitHub/GenericR")
devtools::build()
devtools::install_github("euclia/jaqpotr")
library(bnlearn)
library(yardstick)
library(tidyverse)
# Here we use Mathews Correlation Coefficient to compare the different methodologies.
# It is regarded as a balanced measure which can be used even if the classes are of
# very different sizes.  A coefficient of +1 represents a perfect prediction, 0 no better
# than random prediction and -1 indicates total disagreement between prediction and observation.
# When there are more than two labels the MCC will no longer range between -1 and +1. Instead the
# minimum  value will be between -1 and 0 depending on the true distribution.
# The maximum value is always +1. Another possible comparison metric is the Cohen's Kappa.
data <- openxlsx::read.xlsx("C:/Users/user/Desktop/Jaqpot/R/bnlearn/NM_data.xlsx",sheet=6, colNames=T)
#convert all columns to factors
data[] <- lapply(data, as.factor) #lapply returns list so [] keeps the initial data format (data.frame)
# Remove variables with only one category
drops <- c("Dissolution","Immunological.effects")
data <- data[ , !(names(data) %in% drops)]
#Check the structure of our dataset
str(data)
df_levels <- list()
for (j in 1:dim(data)[2]){
df_levels[[j]] <- levels(data[,j])
}
# Shuffle data
set.seed(1298)
data <- data[sample(nrow(data)),]
N_folds <- 10
N_data  <- dim(data)[1]
step  <- round(N_data/N_folds)
##################################################
#create an empty network
ug <- bnlearn::empty.graph(names(data))
#add the arcs by assigning a two-column matrix containing the labels of their end-nodes.
#Undirected arcs are represented as their two possible orientations
bnlearn::arcs(ug, check.cycles = TRUE) = matrix(c( "NM.Hazard","Shape", "NM.Hazard","Nanoparticle",
"NM.Hazard", "Surface.area",  "NM.Hazard",
"Surface.charge",  "NM.Hazard","Surface.coatings",  "NM.Hazard",
"Surface.reactivity",  "NM.Hazard", "Aggregation",  "NM.Hazard",
"Particle.size",  "NM.Hazard","Administration.route",  "NM.Hazard",
"Study.type",  "NM.Hazard","Cytotoxicity",  "NM.Hazard",
"Neurological.effects",  "NM.Hazard", "Pulmonary.effects",  "NM.Hazard",
"Fibrosis",  "NM.Hazard", "RCNS.effects",   "NM.Hazard", "Genotoxicity",  "NM.Hazard",
"Inflammation", "Nanoparticle","Shape",
"Nanoparticle",  "Surface.reactivity", "Nanoparticle", "Neurological.effects",
"Nanoparticle", "Surface.coatings","Nanoparticle", "Surface.charge",
"Nanoparticle", "Administration.route", "Nanoparticle",  "Fibrosis",
"Shape","Genotoxicity","Surface.area", "Neurological.effects",
"Surface.coatings", "Surface.area",  "Surface.coatings",  "Particle.size",
"Surface.coatings", "Cytotoxicity", "Surface.coatings", "Pulmonary.effects",
"Surface.coatings", "Aggregation",   "Surface.coatings",  "Study.type",
"Pulmonary.effects", "Inflammation","Inflammation","RCNS.effects"),
ncol = 2, byrow = TRUE, dimnames = list(c(), c("from", "to")))
start <- 1
# Test cross-val accuracy of best model
for(i in 1: N_folds){
select <- start:(start+step-1)
if(i ==10){
select <- start:559
}
test <- data[select,]
#Extract observations
observed <- test$NM.Hazard
train <- data[-select,]
# fit the model
training.fit  <- bnlearn::bn.fit(ug, train, method="bayes") #method = "bayes"/"mle"
# Delete all observed nodes
for (k in 1:dim(test)[1]){
for (j in 11:18){
test[k,j] <- NA
}
}
N_test <- dim(test)[1]
pred <- rep(0, N_test)
# Convert all results to factors in order to calculate the confusion matrix
pred <- as.factor(pred)
observed <- as.factor(observed)
levels(pred) <- levels(observed)
for (j in 1:N_test){
# n : number of samples used to average
pred[j] <-  as.character(predict(training.fit, data=test[j,!is.na(test[j,])],
node= "NM.Hazard",prob = T, method = "bayes-lw", n=10000))
#method = "bayes-lw" / "parents"
}
mcc[[i]]  <- yardstick::mcc_vec(observed, pred)
conf[[i]]  <- tibble::tibble(truth = observed,
estimate = pred) %>%
conf_mat(truth, estimate)
acc[[i]]  <-  yardstick::accuracy_vec(observed, pred)#  # Update starting position of test
start <- start+step
}
jaqpotr::deploy.bn(trained.model = training.fit)
unloadNamespace(jaqpotr)
jaqpotr::deploy.bn
